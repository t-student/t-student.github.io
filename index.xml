<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>t-student on t-student</title>
    <link>https://t-student.github.io/</link>
    <description>Recent content in t-student on t-student</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Shiny 101</title>
      <link>https://t-student.github.io/post/shiny01-overview/</link>
      <pubDate>Mon, 09 Apr 2018 00:00:00 +1000</pubDate>
      
      <guid>https://t-student.github.io/post/shiny01-overview/</guid>
      <description>

&lt;p&gt;Shiny is a way to deploy your data analyses in an interactive format that is backed by R.&lt;/p&gt;

&lt;h2 id=&#34;overview-think-inputs-and-outputs&#34;&gt;Overview - Think &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Shiny applications comprise a user interface in the form of a web page (generated from R code), a backend server (that can be hosted on your local machine).&lt;/p&gt;

&lt;p&gt;Before we begin, your goto page for learning about this stuff is &lt;a href=&#34;https://shiny.rstudio.com/articles/&#34; target=&#34;_blank&#34;&gt;https://shiny.rstudio.com/articles/&lt;/a&gt;. Ok, let&amp;rsquo;s build an app - use this template:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage()
server &amp;lt;- function(input, output){}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add input and output functions into the &lt;code&gt;fluidPage&lt;/code&gt; function. We could add any of:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;buttons&lt;/li&gt;
&lt;li&gt;checkboxes (single and grouped)&lt;/li&gt;
&lt;li&gt;date input and range&lt;/li&gt;
&lt;li&gt;file input&lt;/li&gt;
&lt;li&gt;numeric input&lt;/li&gt;
&lt;li&gt;passwords&lt;/li&gt;
&lt;li&gt;radios&lt;/li&gt;
&lt;li&gt;select&lt;/li&gt;
&lt;li&gt;sliders&lt;/li&gt;
&lt;li&gt;text&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;All these functions take similar parameters, the first being a unique id (&lt;code&gt;inputId&lt;/code&gt;) and the second being a label to display to the user. After that there are a bunch of input specific parameters.&lt;/p&gt;

&lt;p&gt;Outputs are plots, tables, text, etc that embed various visualisation elements to the user interface. All these outputs contain one required parameter &lt;code&gt;outputId&lt;/code&gt; which is a unique id for the object. For example, lets add a slider and a placeholder for a histogram that we are going to produce.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  
  sliderInput(inputId = &amp;quot;num&amp;quot;,
              label = &amp;quot;Choose a number please&amp;quot;,
              value = 25, min = 1, max = 100),
  plotOutput(&amp;quot;hist&amp;quot;)
 
)
server &amp;lt;- function(input, output){
  output$hist &amp;lt;- renderPlot({
  	n &amp;lt;- input$num
  	hist(rnorm(n))
  	})
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use the server function to provide the content for the user interface. For each element you need to save the output within the &lt;code&gt;output&lt;/code&gt; list object as a named member. The second thing you need to do is to wrap the object that you want to save in a render function. For example we can render:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;static and interactive tables&lt;/li&gt;
&lt;li&gt;images&lt;/li&gt;
&lt;li&gt;plots&lt;/li&gt;
&lt;li&gt;code blocks&lt;/li&gt;
&lt;li&gt;text&lt;/li&gt;
&lt;li&gt;shiny ui elements&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In the above example we have rendered a histogram based on some dummy data. We can use as many lines of code as we want between the &lt;code&gt;{}&lt;/code&gt; in the render function. Note that you can have multiple reactive variables within a &lt;code&gt;render*()&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;We can access the values that the user selects with the slider in the server function. These are called reactive elements and shiny takes care of the updates. Ok, run the app, you should see something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/shiny101-01.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Final note - to deploy your application you need to save it with the filename &lt;code&gt;app.R&lt;/code&gt;. However, if you have massive UI and server elements you can split the application into two files, one called &lt;code&gt;ui.R&lt;/code&gt; and the other called &lt;code&gt;server.R&lt;/code&gt;. Then, you add all your media content to the folder. After that you can deploy to &lt;a href=&#34;http://www.shinyapps.io/&#34; target=&#34;_blank&#34;&gt;shinyapps.io&lt;/a&gt; but first you need to create an account. After you have created an account, all you need to do is press publish application in the RStudio.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Shiny Stage 2 - Reactivity</title>
      <link>https://t-student.github.io/post/shiny01-stage2/</link>
      <pubDate>Mon, 09 Apr 2018 00:00:00 +1000</pubDate>
      
      <guid>https://t-student.github.io/post/shiny01-stage2/</guid>
      <description>

&lt;p&gt;Shiny is a way to deploy your data analyses in an interactive format that is backed by R.&lt;/p&gt;

&lt;h2 id=&#34;shiny-next-steps&#34;&gt;Shiny Next Steps&lt;/h2&gt;

&lt;p&gt;In an earlier post we went over how to get a basic Shiny app together and deployed to &lt;a href=&#34;http://www.shinyapps.io/&#34; target=&#34;_blank&#34;&gt;shinyapps.io&lt;/a&gt;. Now we will look more at reactivity and customise appearance using tech like html5 and css from within RStudio. Specifically, we put a bit more focus onto the server side.&lt;/p&gt;

&lt;h2 id=&#34;customising-reactions&#34;&gt;Customising Reactions&lt;/h2&gt;

&lt;p&gt;So earlier we saw that we can update various outputs based on a users input. However, we can also reactivity to trigger code on the server side or output after some chain of reactive updates or, we could postpone updates until a user explicity requests them through an update button.&lt;/p&gt;

&lt;p&gt;The first thing to understand about reactive elements is that they work together with reactive functions. For example, the &lt;code&gt;renderPlot&lt;/code&gt; function is a reactive function that expects to receive reactive variables such as &lt;code&gt;input$num&lt;/code&gt; discussed last time. The input reactive values notify the observer whenever there is a state change and the observer function responds.&lt;/p&gt;

&lt;p&gt;There are about 7 functions you need to know to work with reactivity a large proportion being the &lt;code&gt;render*()&lt;/code&gt; functions, but there are a few others we discuss here.&lt;/p&gt;

&lt;h3 id=&#34;reactive&#34;&gt;&lt;code&gt;reactive&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;You can modularise code by using the function named &lt;code&gt;reactive&lt;/code&gt;. With this you can, for example, share the same data across multiple reactive functions. However, in order to access the data stored within &lt;code&gt;reactive&lt;/code&gt;  you need to invoke the data name as if you were calling a function. Below is an example to make it clear. We define a reactive data set and assign it to &lt;code&gt;x&lt;/code&gt;. Whenever the input gets updated by the user the reactive method updates x. Now, within the &lt;code&gt;render&lt;/code&gt; functions what we need to do is call &lt;code&gt;x&lt;/code&gt; like we would call a function.&lt;/p&gt;

&lt;p&gt;Note that &lt;code&gt;reactive&lt;/code&gt; caches its value &lt;em&gt;until it becomes invalid&lt;/em&gt; due to user input.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  
  sliderInput(inputId = &amp;quot;num&amp;quot;,
              label = &amp;quot;Choose a number please&amp;quot;,
              value = 25, min = 1, max = 100),
  textInput(inputId = &amp;quot;title&amp;quot;,
            &amp;quot;Provide title&amp;quot;,
            value = &amp;quot;Histogram of normal RV&amp;quot;),
  plotOutput(&amp;quot;hist&amp;quot;),
  verbatimTextOutput(&amp;quot;stats&amp;quot;)
  
)
server &amp;lt;- function(input, output){
  
  # New reactive part !!!
  x &amp;lt;- reactive({rnorm(input$num)})
  
  output$hist &amp;lt;- renderPlot({
    mymain &amp;lt;- input$title
    # Call x as you would a function !!!
    hist(x(), main = mymain)
  })
  
  output$stats &amp;lt;- renderPrint({
    summary(x())
  })
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;isolate&#34;&gt;&lt;code&gt;isolate&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;isolate&lt;/code&gt; function is the opposite of the &lt;code&gt;reactive&lt;/code&gt; function. This function makes user specified input inert. For example we could make the graph title not update until we change the slider by wrapping the title in an &lt;code&gt;isolate&lt;/code&gt; call as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Note that here we wrap the title and make it inert
# until a user updates the slider.
output$hist &amp;lt;- renderPlot({
    mymain &amp;lt;- isolate(input$title)
    hist(x(), main = mymain)
  })
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;server-side-triggers&#34;&gt;Server-side Triggers&lt;/h2&gt;

&lt;p&gt;Maybe we want to save a file to the system or do something that does not result in a UI update. In order to do this we implement a basic UI with a button for the user to click that we use to trigger the &lt;code&gt;observeEvent&lt;/code&gt; function. This function can wrap a whole bunch of R code (using reactive elements if we want it to do so) but it is only run if the button is pressed, i.e. it is inert to all other updates. However, if the user clicks the button then code encapsulated in &lt;code&gt;observeEvent&lt;/code&gt; will use all the latest reactive values. Here is an example that prints the number of clicks.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  actionButton(inputId = &amp;quot;clicks&amp;quot;,
               label = &amp;quot;Click me&amp;quot;)
)
server &amp;lt;- function(input, output){
  observeEvent(input$clicks, {
    print(as.numeric(input$clicks))
  }) 
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For more information, see the action buttons article on the shiny site.&lt;/p&gt;

&lt;p&gt;There is a second server-side trigger called &lt;code&gt;observe&lt;/code&gt; but in practice &lt;code&gt;observeEvent&lt;/code&gt; is more useable.&lt;/p&gt;

&lt;h2 id=&#34;delay-reactions-with-eventreactive&#34;&gt;Delay Reactions with &lt;code&gt;eventReactive&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;This enables us to do things like wait until a user has finished entering the title before we do an update. Here we add a button that will allow the user to control when the output updates.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage( 
  sliderInput(inputId = &amp;quot;num&amp;quot;,
              label = &amp;quot;Choose a number please&amp;quot;,
              value = 25, min = 1, max = 100),
  textInput(inputId = &amp;quot;title&amp;quot;,
            &amp;quot;Provide title&amp;quot;,
            value = &amp;quot;Histogram of normal RV&amp;quot;),
  actionButton(inputId = &amp;quot;go&amp;quot;,
               label = &amp;quot;Update&amp;quot;),
  plotOutput(&amp;quot;hist&amp;quot;)
  
)
server &amp;lt;- function(input, output){  
  x &amp;lt;- eventReactive(input$go, {rnorm(input$num)})
  
  output$hist &amp;lt;- renderPlot({
    mymain &amp;lt;- isolate(input$title)
    hist(x(), main = mymain)
  })
  
  output$stats &amp;lt;- renderPrint({
    summary(x())
  })
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;manage-state-with-reactivevalues&#34;&gt;Manage State with &lt;code&gt;reactiveValues&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;As a rule shiny does not permit you the way to update input values. However, sometimes this might be userful to do and so shiny provides a mechanism to construct your own reactive values. You might use this in a situation where you want to trigger a data update conditionally, like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/shiny102-usingreactiveVal.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the above example the user is specifying whether they want to generate Normal or Uniform data. Here is an implementation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  
  actionButton(inputId = &amp;quot;norm&amp;quot;,label = &amp;quot;Normal&amp;quot;),
  actionButton(inputId = &amp;quot;unif&amp;quot;,label = &amp;quot;Uniform&amp;quot;),
  plotOutput(&amp;quot;hist&amp;quot;)
  
)
server &amp;lt;- function(input, output){
  
  rv &amp;lt;- reactiveValues(x = rnorm(100))
  
  observeEvent(input$norm, {rv$x &amp;lt;- rnorm(100)})
  observeEvent(input$unif, {rv$x &amp;lt;- runif(100)})
  
  output$hist &amp;lt;- renderPlot({
    hist(rv$x)
  })
  
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;reactiveValues&lt;/code&gt; are starting to move into a little more technical abstract ideas so, just to recap:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;reactiveValues&lt;/code&gt; create a list of reactive values&lt;/li&gt;
&lt;li&gt;you can manipulate these values (usually with &lt;code&gt;observeEvent&lt;/code&gt;) and an action button&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Final food for thought:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;code outside the server function will be run once per R session whereas code inside the server function will be run once per end user. Take home - if you don&amp;rsquo;t need to run the code more than once per user then put it outside the server function.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thanks for reading!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Shiny Stage 3 - UI customisation</title>
      <link>https://t-student.github.io/post/shiny01-stage3/</link>
      <pubDate>Mon, 09 Apr 2018 00:00:00 +1000</pubDate>
      
      <guid>https://t-student.github.io/post/shiny01-stage3/</guid>
      <description>

&lt;p&gt;OK, so we have gone over the basic setup and dug a bit more into the reactivity functionality. Now we are going to look at UI extensions aka html5 and css.&lt;/p&gt;

&lt;h2 id=&#34;working-with-the-html&#34;&gt;Working with the HTML&lt;/h2&gt;

&lt;p&gt;The functions in the UI create HTML. So why don&amp;rsquo;t we add some static content? Shiny comes with a series of &lt;code&gt;tags&lt;/code&gt; functions that will create HTML for you. Here is an example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  
  # a tag is an anchor
  tags$h1(&amp;quot;Title 1&amp;quot;),
  tags$a(href = &amp;quot;www.rstudio.com&amp;quot;, &amp;quot;RStudio&amp;quot;),
  tags$p(&amp;quot;This is my app para 1.&amp;quot;),
  tags$p(&amp;quot;This is my app para &amp;quot;, tags$strong(&amp;quot;2!!&amp;quot;)),
  tags$br(), # Page break
  tags$p(style = &amp;quot;font-family:Impact&amp;quot;, &amp;quot;This is my app para 3 with a custom style!!!&amp;quot;),
  tags$hr(), # Horizontal rule
  tags$code(&amp;quot;This is my app&amp;quot;),
  tags$br(), # Page break
  # To use your own media create a www folder and chuck your
  # media in there then reference as follows:
  tags$img(height = 100, width = 250, src = &amp;quot;shinyzombie.jpg&amp;quot;),
  tags$br(), # Page break
  tags$br(), # Page break
  
  HTML(&amp;quot;&amp;lt;h2&amp;gt;Just for completeness we can write raw HTML if we want to!!!&amp;lt;/h2&amp;gt;&amp;quot;),
  
  actionButton(inputId = &amp;quot;clicks&amp;quot;,
               label = &amp;quot;Click me&amp;quot;)
  
)
server &amp;lt;- function(input, output){
  observeEvent(input$clicks, {
    print(as.numeric(input$clicks))
  })
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;messing-with-the-layout&#34;&gt;Messing with the Layout&lt;/h2&gt;

&lt;p&gt;We can place the UI elements wherever we want to. The main functions that we use to do this are &lt;code&gt;fluidRow()&lt;/code&gt; and &lt;code&gt;column&lt;/code&gt; which both insert &lt;code&gt;div&lt;/code&gt;s. &lt;code&gt;fluidRow()&lt;/code&gt; will divide you app into rows creating as many as you want. Next you can create (up to 12) columns within a row specifying both the width and offset of each column like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  fluidRow(column(3),  # Takes up 3 units of width
           column(5)), # Takes up 5 units of width
  fluidRow(
           column(4, offset = 8) # Offset the start of the column
           )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, if you actually want to see something you pass it to the row or column function like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  
  fluidRow(column(3, tags$p(&amp;quot;Hi!!! :)&amp;quot;)),  # Takes up 3 units of width
           column(5, 
                  sliderInput(inputId = &amp;quot;num&amp;quot;,
                              label = &amp;quot;Choose a number please&amp;quot;,
                              value = 25, min = 1, max = 100))), 
  fluidRow(
    column(6, offset = 1, 
           plotOutput(&amp;quot;hist&amp;quot;)) 
  )
)
server &amp;lt;- function(input, output){
  output$hist &amp;lt;- renderPlot({
    n &amp;lt;- input$num
    hist(rnorm(n))
  })
}

shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;stacking-layouts&#34;&gt;Stacking Layouts&lt;/h2&gt;

&lt;p&gt;Panels are the basic UI aggregate element. To place a series of elements together into a panel we wrap them with the &lt;code&gt;wellPanel&lt;/code&gt; function. In total there are 12 types of panels supported by shiny:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Function&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;absolutePanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rigid&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;conditionalPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Determines whether a panel is visible&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;fixedPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Does not scroll&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;headerPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Panel for title - use with &lt;code&gt;pageWithSidebar()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;inputPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;A grouping panel&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;mainPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Displaying output - use with &lt;code&gt;pageWithSidebar()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;navlistPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Stacking&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;sidebarPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Sidebar of inputs - use with &lt;code&gt;pageWithSidebar()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;tabPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Stackable&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;tabsetPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Multiple stacked&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;titlePanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Apps title&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;wellPanel()&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Panel with grey background&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If you want to stack things on top of each other start with &lt;code&gt;tabPanel()&lt;/code&gt;. This is a small UI of its own and is a convenient way to break up the various elements of your app. These functions are designed to work in conjunction with &lt;code&gt;tabsetPanel()&lt;/code&gt;, &lt;code&gt;navlistPanel&lt;/code&gt; and &lt;code&gt;navbarPage()&lt;/code&gt;. Here is a quick example.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  
  tabsetPanel(
    tabPanel(&amp;quot;tab 1&amp;quot;, 
             sliderInput(inputId = &amp;quot;num&amp;quot;,
                                  label = &amp;quot;Choose a number please&amp;quot;,
                                  value = 25, min = 1, max = 100)
             ),
    tabPanel(&amp;quot;tab 1&amp;quot;, 
             plotOutput(&amp;quot;hist&amp;quot;)
             )
  )
)
server &amp;lt;- function(input, output){
  output$hist &amp;lt;- renderPlot({
    n &amp;lt;- input$num
    hist(rnorm(n))
  })
}


shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/shinytabpanel.png&#34; alt=&#34;Shiny `tabPanel` Output&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now &lt;code&gt;navlistPanel()&lt;/code&gt; is analogous to the &lt;code&gt;tabsetPanel()&lt;/code&gt; except it creates your navigation in a sidebar.&lt;/p&gt;

&lt;h2 id=&#34;precanned-layouts&#34;&gt;Precanned Layouts&lt;/h2&gt;

&lt;p&gt;We should have talked about this first&amp;hellip; Anyway, nevermind. These are convenience wrappers that let you put together a layout very quickly. The most common is &lt;code&gt;sidebarLayout()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(shiny)

ui &amp;lt;- fluidPage(
  
  sidebarLayout(
    sidebarPanel(sliderInput(inputId = &amp;quot;num&amp;quot;,
                             label = &amp;quot;Choose a number please&amp;quot;,
                             value = 25, min = 1, max = 100)),
    mainPanel(plotOutput(&amp;quot;hist&amp;quot;))
    
  )
)
server &amp;lt;- function(input, output){
  output$hist &amp;lt;- renderPlot({
    n &amp;lt;- input$num
    hist(rnorm(n))
  })
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Other options are &lt;code&gt;fixedPage&lt;/code&gt; and &lt;code&gt;navbarPage()&lt;/code&gt;. Note when you use &lt;code&gt;navbarPage()&lt;/code&gt; you do so by replace the &lt;code&gt;fluidPage()&lt;/code&gt; call. You can use the &lt;code&gt;navbarPage()&lt;/code&gt; with &lt;code&gt;navbarMenu()&lt;/code&gt; to give you drop down lists in the tabs. We can go further, but there is a tutorial on more advanced dashboards &lt;a href=&#34;https://www.rstudio.com/resources/webinars/dynamic-dashboards-with-shiny/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;css&#34;&gt;CSS&lt;/h2&gt;

&lt;p&gt;Shiny enables us to stylise our site with our own branding. The way that we do this is to link with a CSS file, writing a global CSS header or write the CSS into a tags style attribute. We can then apply CSS to tags, or classes or ids. This forms a hierarchy that we can use to automatically deal with various aspects of the site overriding the bits that we want to have different.&lt;/p&gt;

&lt;p&gt;Shiny makes use of the Bootstrap 3 CSS framework, see &lt;a href=&#34;https://getbootstrap.com/&#34; target=&#34;_blank&#34;&gt;https://getbootstrap.com/&lt;/a&gt;. To use this we can create a &lt;code&gt;fluidPage()&lt;/code&gt; function that contains &lt;code&gt;&amp;lt;div class=&amp;quot;container-fluid&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;&lt;/code&gt;. Alternatively we could specify our own CSS file using the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ui &amp;lt;- fluidPage(
  tags$head(
    tags$link(
        rel = &amp;quot;stylesheet&amp;quot;,
        type = &amp;quot;text/css&amp;quot;
        href = &amp;quot;myfile.css&amp;quot;
      )
    )
  
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or you can even just call &lt;code&gt;includeCSS(&amp;quot;myfile.css&amp;quot;)&lt;/code&gt; which will copy a CSS into every page. To learn more about CSS there is a free tutorial at &lt;a href=&#34;https://www.codecademy.com/tracks/web&#34; target=&#34;_blank&#34;&gt;https://www.codecademy.com/tracks/web&lt;/a&gt; which covers both HTML and CSS in about 7 hours.&lt;/p&gt;

&lt;h2 id=&#34;google-analytics&#34;&gt;Google Analytics&lt;/h2&gt;

&lt;p&gt;A final note, you can incorporate the google analytics into your application pretty easily if you want to have it, see &lt;a href=&#34;https://shiny.rstudio.com/articles/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;what-now&#34;&gt;What Now?&lt;/h2&gt;

&lt;p&gt;Build an app!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Zombies 101</title>
      <link>https://t-student.github.io/post/basicbayesian/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +1000</pubDate>
      
      <guid>https://t-student.github.io/post/basicbayesian/</guid>
      <description>

&lt;p&gt;I find the &lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34; target=&#34;_blank&#34;&gt;Statistical Rethinking&lt;/a&gt; text very helpful in conveying Bayesian concepts. Here I simply try to condense some of the introductory material. The text is supported with R and Python implementations and there is a youtube lecture series on which the text is based.&lt;/p&gt;

&lt;h2 id=&#34;ok-bayesian-analysis&#34;&gt;OK, Bayesian Analysis?&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start with inference. What we are talking about here is about using the information available to you in order to arrive at rational conclusions that your mum still won&amp;rsquo;t have a bar of. Bayesian analysis is a fairly snappy way to go about this task.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/pirahna.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s get serious and work up to laying down some definitions and notation. First, the breed of inference we are interested in here is &lt;a href=&#34;https://en.wikipedia.org/wiki/Statistical_inference&#34; target=&#34;_blank&#34;&gt;statistical inference&lt;/a&gt;. Statistical inference involves using observations in a framework of presupposition and statistical models that aim at a logical conclusions. Generally we want to be able to make some statements about a scientific question relating to a population of interest.&lt;/p&gt;

&lt;p&gt;Examples - we flip a coin obtained from the local mint 10 times and it produces 7 heads. Should we believe the coin is fair? What about the other coins produced by the mint? We measure the heights of 10 men that play for a professional basket ball team. What does this tell us about the height of all men? &lt;strong&gt;Bayesian analysis&lt;/strong&gt; gives us a formal method to combine what we already know with new evidence and characterises the remaining uncertainty in probability.&lt;/p&gt;

&lt;h2 id=&#34;the-standard-zombie-example-of-bayesian-inference&#34;&gt;The Standard (Zombie) Example of Bayesian Inference&lt;/h2&gt;

&lt;p&gt;In a bayesian analysis we characterise uncertainty using a small bag of tools. Let&amp;rsquo;s introduce a few&amp;hellip;&lt;/p&gt;

&lt;h3 id=&#34;a-prior&#34;&gt;A Prior&lt;/h3&gt;

&lt;p&gt;The Bayesian framework places our existing knowledge in a probability distribution and a probability distribution simply captures how likely a variable of interest is across its possible range. For example, the proportion of zombies hanging around the local shopping mall must be somewhere between zero and 100%&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; of all the individuals there. Now, perhaps we are sceptical, but not entirely calm, about the notion that zombies exist. So let&amp;rsquo;s start this off and believe that we believe that the most likely situation is that there are no-need-for-tears-at-bedtime zero zombies. However, because we subscribe to the philosophy of the belt and braces brigade, let&amp;rsquo;s assume that it could be the case that up to 30% of the individuals in the mall are of the zombie variety. If we had to draw a picture our relative belief we might produce something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/zombiesprior.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I generated that snappy curve from a &lt;a href=&#34;https://en.wikipedia.org/wiki/Beta_distribution&#34; target=&#34;_blank&#34;&gt;Beta distribution&lt;/a&gt; by using paramter values equal to 1 and 27. In a more mathy bent we say:&lt;/p&gt;

&lt;p&gt;$$
\theta \sim Beta(1, 27)
$$&lt;/p&gt;

&lt;p&gt;In words - theta is distributed as a random variable originated from a beta distribution with shape parameters 1 and 27 - you can see why we favour the mathy version.&lt;/p&gt;

&lt;h3 id=&#34;likelihood&#34;&gt;Likelihood&lt;/h3&gt;

&lt;p&gt;Now, let&amp;rsquo;s go to the mall and pick out 20 people at random under the assumption that all individuals have the same probability of being a zombie. However, not one of the people in the sample tries to even take a nimble at us and so we conclude (with perhaps undue certainty) that the sample we picked contained no zombies. We can, again, make this more formal by saying that the data generating process was a &lt;a href=&#34;https://en.wikipedia.org/wiki/Binomial_distribution&#34; target=&#34;_blank&#34;&gt;Binomial distribution&lt;/a&gt; where one of the parameters is our sample size and the other parameter represents the probability that a randomly selected individual is a zombie. Mathematically, we have:&lt;/p&gt;

&lt;p&gt;$$
y|\theta \sim Bin(20, \theta)
$$&lt;/p&gt;

&lt;p&gt;and therefore conditional on $\theta$ any given sample of mall people stands a chance of containing a zombie.&lt;/p&gt;

&lt;h3 id=&#34;posterior&#34;&gt;Posterior&lt;/h3&gt;

&lt;p&gt;In light of our sample data our state of belief has changed and we maybe feeling a bit better about going to the shops. Anyway, in the Bayesian world, a simple relationship allows us to characterise our new knowledge, again in terms of a probability distribution known as the posterior&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. The relationship between the posterior, prior and likelihood is derived as a consequence of the laws of probability&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; and has the form:&lt;/p&gt;

&lt;p&gt;$$
Posterior = \frac{Likelihood \times Prior}{Average \ Likelihood}
$$&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;average likelihood&lt;/em&gt; bit is computed over all the possible values of the parameter $\theta$ - the proportion of zombies which must be somewhere between zero to 1. Fortunately, we don&amp;rsquo;t have to know how to work out the above directly because the product of a Beta prior and a Binomial likelihood is well known. Specifically, it is another Beta distribution but with different parameters based on the the data we observed and the prior parameters. The first parameter of the posterior beta distribution is $a + y$ and the second is $b + n - y$. In our case, a = 1, y = 0, b = 27 and n = 20 so we have the posterior is:&lt;/p&gt;

&lt;p&gt;$$
Pr(\theta|y) \sim Beta(1, 47)
$$&lt;/p&gt;

&lt;p&gt;If we were to draw another graph of the (new) relative strength of beliefs it would look something like the following (new beliefs in red):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/zombiesposterior.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So whereas initially we were 90% certain that less than 8.5% of the population are zombies, now we are 90% certain that less than 5% of the population are zombies. We have reduced our uncertainty by leveraging our existing beliefs and our sample observations.&lt;/p&gt;

&lt;h2 id=&#34;grid-approximation&#34;&gt;Grid Approximation&lt;/h2&gt;

&lt;p&gt;Unfortunately, the calculations are rarely this simple - we rarely have &lt;a href=&#34;https://en.wikipedia.org/wiki/Conjugate_prior&#34; target=&#34;_blank&#34;&gt;conjugate&lt;/a&gt; pairs of priors and likelihood like I contrived in the above example. However, we can get around this using sampling. In its simplest form we can use a &lt;em&gt;grid approximation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;In R the following code shows how this might play out. We first set up a posterior distribution and then we sample with replacement to get an approximation of the posterior distribution.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# This is the range of parameter values and defines the precision
# to which we can estimate the parameter of interest. 
mygrid &amp;lt;- seq(0, 1, length.out = 1000)
# Defines our prior beliefs
prior &amp;lt;- dbeta(mygrid, 1, 27)
# Defines the relative likelihood of the data (zero zombies out of 20) 
# across all the possible parameter values
likelihood &amp;lt;- dbinom(0, size = 20, prob = mygrid)
# Compute the posterior and normalise it
posterior &amp;lt;- likelihood * prior 
posterior &amp;lt;- posterior / sum(posterior)

# This is analytic posterior - generally we don&#39;t have the
# luxury of knowing this.
analyticpost &amp;lt;- dbeta(mygrid, 1, 47)

# Sample from the posterior distribution
myposteriorsample &amp;lt;- sample(mygrid, prob = posterior, size = 1e4, replace = T)

# Plot the samples
plot(myposteriorsample, type = &amp;quot;p&amp;quot;, 
     xlab = &amp;quot;Sample index&amp;quot;,
     ylab = &amp;quot;Proportion of zombies&amp;quot;)

# Plot the analytical and the sampled posterior distribution 
x.idx &amp;lt;- density(myposteriorsample)$x
y.den &amp;lt;- density(myposteriorsample)$y

plot(mygrid, analyticpost, type = &amp;quot;l&amp;quot;,
     xlab = &amp;quot;Proportion of zombies&amp;quot;,
     ylab = &amp;quot;Relative likelihood&amp;quot;, xlim = c(0, 0.3))
lines(x.idx, y.den, col = &amp;quot;red&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Samples from posterior&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Analytic and sampled posterior (red) probability density&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/zombiesamples.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/zombiesmcmc.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Clearly the relatively likelihood at approximately zero is underestimated by the sampling approach but this is to do with the available precision and could be improved by increasing the resolution of the grid.&lt;/p&gt;

&lt;p&gt;The grid approximation is useful to get some understanding into the mechanics but does not scale well to more complex problems where we would more commonly use Markov Chain Monte Carlo &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo&#34; target=&#34;_blank&#34;&gt;MCMC&lt;/a&gt; simulations.&lt;/p&gt;

&lt;h2 id=&#34;posterior-summaries&#34;&gt;Posterior Summaries&lt;/h2&gt;

&lt;p&gt;It is interesting to consider (moreso if you are a bit nerdy) how you might summarise our new state of knowledge inherent in the posterior distribution. There are a few options to condense what it is telling us into a 10 second soundbite for people without patience or interest.&lt;/p&gt;

&lt;p&gt;First, we can compute a 95% credible interval as below, which tells us that there is a 95% probability that the proportion of zombies in the community is between zero and 7.5%. A similar interval is the Highest Posterior Density Interval, but this interval is the narrowest interval that contains the specified probability mass. For this example it turns out to be about the same as the credible interval but that won&amp;rsquo;t always be the case. We can obtain the point estimates of the mean, median and mode, which turn out to be 2.1%, 1.4% and 0.37%.&lt;/p&gt;

&lt;p&gt;All of these approaches are effectively &lt;a href=&#34;https://en.wikipedia.org/wiki/Data_reduction&#34; target=&#34;_blank&#34;&gt;data reduction techniques&lt;/a&gt; - we have reduced the posterior probability distribution to a one or two numbers in order to make what it is telling us more digestable.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Credible interval
quantile(myposteriorsample, c(0.025, 0.975))
rethinking::PI(myposteriorsample, 0.95)

# HPDI
rethinking::HPDI(myposteriorsample, 0.975)

# Measures of centrality
mean(myposteriorsample)
median(myposteriorsample)

# Mode
rethinking::chainmode(myposteriorsample)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another thing we can do is define a &lt;strong&gt;loss function&lt;/strong&gt; and characterise the cost of adopting a particular summary under given conditions. This mostly comes into play when we want to make a &lt;a href=&#34;https://en.wikipedia.org/wiki/Decision_theory&#34; target=&#34;_blank&#34;&gt;decision&lt;/a&gt; such as whether we should go to the shops or not. Different loss functions imply different point estimates and a common loss function is to assume that the loss is proportional to the absolute difference between your decision and the correct answer. We can compute the loss over the entire parameter range using the following code, which gives us an value of 1.4%, identical to the median computed previous. In reality the loss function would need more thought and we might make the cost function penalise being wrong more harshly as might be well advised since encountering a zombie has stark &lt;a href=&#34;https://en.wikipedia.org/wiki/Metaphysics&#34; target=&#34;_blank&#34;&gt;metaphyscial&lt;/a&gt; implications.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;loss &amp;lt;- sapply(mygrid, function(d) sum(analyticpost * abs(d - mygrid)))
mygrid[which.min(loss)]loss &amp;lt;- sapply()

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;model-checking&#34;&gt;Model Checking&lt;/h2&gt;

&lt;p&gt;I know I have been banging for a bit now, but this last bit is important so stick with it. Here is the thing - all Bayesian models are generative so once you have a posterior distribution of the parameter of interest you can simulate new data. Ideally the predictions we make should contain both uncertainty in the distribution associated with a parameter and the uncertainty about the parameter itself. For example, if we use $\theta = 0.05$ or $\theta = 0.1$ we get a distribution of zombies like the figures below. So if there is a 5% probability that an individual is a zombie we would expect to zero or one zombies most of the time. However, if there was a 10% probability that an individual is a zombie we would mostly expect to see 1 or 2 in a sample of 20. In a nutshell, when $\theta = 0.05$ we expect to see a zero count of zombies more often than we do if $\theta = 0.1$.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Proportion of zombies 5%&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;10%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/zombiesim1.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/zombiesim2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now, the thing is, $\theta$ also has uncertainty as we have described by the posterior distribution and ideally we want to propagate this uncertainty into our predictions. To do this we average all of the prediction distributions together using the posterior of each value of $\theta$. This gives us a &lt;a href=&#34;https://en.wikipedia.org/wiki/Posterior_predictive_distribution&#34; target=&#34;_blank&#34;&gt;posterior predictive distribution&lt;/a&gt;, which is actually a lot easier to produce than to explain, the following gets us to where we want to be.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Distribution of observed zombies theta = 0.05
z1 &amp;lt;- rbinom(1e4, size = 20, prob = 0.05)
# Distribution of observed zombies averaged across the posterior distribution
z2 &amp;lt;- rbinom(1e4, size = 20, prob = myposteriorsample)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/zombiesim3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this case we can be quite conforted by the fact that the posterior predictive aligns fairly well with what we observed since it looks like we generally encounter small numbers (0 or 1) zombies in our daily trip to the shops.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;OK, maybe more than 100% if you live in Jesmond.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;If you are starting to think that everything is uncertain in a Bayesian world then you may be onto something.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;That I refuse to go into right now.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Installing Python on Windows 10</title>
      <link>https://t-student.github.io/post/installpython3/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +1100</pubDate>
      
      <guid>https://t-student.github.io/post/installpython3/</guid>
      <description>

&lt;p&gt;I have decided to start doing more coding in Python, so I needed to install it. The title says it all but this is just to record what I did. In brief:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;install a package manager (equivalent to apt in linux)&lt;/li&gt;
&lt;li&gt;use python to install pip (a package manager for python)&lt;/li&gt;
&lt;li&gt;install an environment manager so that you can support different sets of dependencies with minimal hassle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I started with the instructions &lt;a href=&#34;http://docs.python-guide.org/en/latest/starting/install3/win/#install3-windows&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. They work fairly seemlessly. However, the following is what I did.&lt;/p&gt;

&lt;h2 id=&#34;installing-package-manager&#34;&gt;Installing Package Manager&lt;/h2&gt;

&lt;p&gt;You need to do this with administrator privaleges otherwise it won&amp;rsquo;t work. I used the instructions found &lt;a href=&#34;https://chocolatey.org/install#installing-behind-a-proxy&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; that are for installing where you are behind a proxy.&lt;/p&gt;

&lt;p&gt;To launch a command prompt with admin privaleges do Start, then type cmd, right click on the command launcher and choose more, then run as an admin.&lt;/p&gt;

&lt;h2 id=&#34;installing-python-3&#34;&gt;Installing Python 3&lt;/h2&gt;

&lt;p&gt;Again use administrator privaleges to invoke &lt;code&gt;python -m pip install -U pip&lt;/code&gt; at the command line.&lt;/p&gt;

&lt;h2 id=&#34;pipenv-and-virtualenv-environment-manager&#34;&gt;Pipenv and Virtualenv environment manager&lt;/h2&gt;

&lt;p&gt;This was a bit fiddly but purely down to the fact that the default install relies only on user privaleges. You end up with an error &lt;code&gt;&#39;pipenv&#39; is not recognized as an internal or external command&lt;/code&gt; because the path is not updated.&lt;/p&gt;

&lt;p&gt;Once complete, run &lt;code&gt;py -m site --user-site&lt;/code&gt; which reports a directory path. It will be something like &lt;code&gt;C:\Users\mjones\AppData\Roaming\Python\Python36\site-packages&lt;/code&gt;. What you need to do is to add a directory to the &lt;code&gt;PATH&lt;/code&gt; environment variable that is the same as this user path but ends with &lt;code&gt;Scripts&lt;/code&gt; rather than &lt;code&gt;site-packages&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Pipenv manages library dependencies on a per project basis. You use &lt;code&gt;pipenv&lt;/code&gt; instead of &lt;code&gt;pip&lt;/code&gt;. For example, to install the &lt;code&gt;requests&lt;/code&gt; package, change into your project’s directory (or just an empty directory for this tutorial) and run:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd myproject
pipenv install requests
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pipenv will install the requests library and create a Pipfile for you in your project’s directory. The Pipfile is used to track which dependencies your project needs in case you need to re-install them, such as when you share your project with others. For more info, see &lt;a href=&#34;http://docs.python-guide.org/en/latest/dev/virtualenvs/#virtualenvironments-ref&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;virtualenv&lt;/code&gt; is a tool to create isolated Python environments. &lt;code&gt;virtualenv&lt;/code&gt; creates a folder which contains all the necessary executables to use the packages that a Python project would need.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Logistic Regression - Power Analysis</title>
      <link>https://t-student.github.io/post/logistic01-powersim/</link>
      <pubDate>Fri, 16 Feb 2018 00:00:00 +1100</pubDate>
      
      <guid>https://t-student.github.io/post/logistic01-powersim/</guid>
      <description>

&lt;p&gt;If you have multiple treatment options that lead to different outcomes, you will only be able to detect a difference in the average outcome under conditions where there is sufficient &lt;em&gt;statistical power&lt;/em&gt; to do so. &lt;em&gt;Statistical power&lt;/em&gt; is the probability that we detect an effect when there really is an effect to be detected. As statistical power increases the probability of making a Type II error (concluding there is no effect when, in fact, there is one) decreases.&lt;/p&gt;

&lt;p&gt;Statistical power is affected by the size of the effect, the statistical significance criteria (typically 0.05) and the size of the sample. It is possible to miss a real effect simply by not taking a large enough sample. Power analyses help us by allowing us to explore the experimental conditions for a range of sample sizes.&lt;/p&gt;

&lt;p&gt;In this post we look at how power varies in a logistic regression setting. First we compare treatment groups directly and then we compare treatment groups stratified by a characteristic of the mother that is also associated with the response of interest - e.g. a genetic disposition for a disease.&lt;/p&gt;

&lt;h2 id=&#34;rct-steroidal-treatments-for-reducing-the-risk-of-having-an-ashthmatic-child&#34;&gt;RCT Steroidal Treatments for Reducing the Risk of having an Ashthmatic Child.&lt;/h2&gt;

&lt;p&gt;Consider a steroidal intervention that influences the likelihood of having an ashmatic child. Assume a pilot study suggests the observed proportion of asthmatic kids in the control arm is 17.4% and in the treatment arm is 10%. This implies a relative risk (RR) of 0.575 - the probability of a kid having ashmatic in the treatment arm is 0.58 times that in the control arm.&lt;/p&gt;

&lt;p&gt;Robert Grant gives us a way to convert odds-ratios (OR) to RR &lt;a href=&#34;https://robertgrantstats.wordpress.com/2014/01/27/how-to-convert-odds-ratios-to-relative-risks/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, specifically $RR = \frac{OR}{1 – p + (p \times OR)}$. Turning this formula around we find the unadjusted odds-ratio is about 0.5329 - the odds of an &amp;ldquo;average&amp;rdquo; parent having an asthmatic kid in the treatment arm are around 0.53 times the odds of an equivalent parent having an asthmatic kid in the control arm.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s say we want to work out a sample size for a formal parallel arm RCT. We suspect that we will only be able to get 650 people and the odds of an event in the intervention group are about half the odds of an event in the control group. What sort of power do we expect to obtain with this sample?&lt;/p&gt;

&lt;h3 id=&#34;method&#34;&gt;Method&lt;/h3&gt;

&lt;p&gt;Assume:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Balanced groups (randomly selected) of 325 mothers per arm&lt;/li&gt;
&lt;li&gt;Proportion having asthmatic kid in control is 0.174&lt;/li&gt;
&lt;li&gt;The odds ratio associated with the steroidal treatment is 0.5329&lt;/li&gt;
&lt;li&gt;Adopt a linear predictor solely based on group membership&lt;/li&gt;
&lt;li&gt;Simulate a sample of kids by:

&lt;ol&gt;
&lt;li&gt;Computing probability of asthma based on the exponentiated logits.&lt;/li&gt;
&lt;li&gt;Draw from binomial distribution parameterised as $Bin(n, p)$ where n is the (total) sample size and p the probability of ashmatic child.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Fit a GLM with specification y ~ grp using the sample data and from this predict the probability for the control and treatment groups along with the difference in probability and estimated OR&lt;/li&gt;
&lt;li&gt;Bootstrap (299 replicates) to get the 0.025 and 0.975 quantiles of the difference&lt;/li&gt;
&lt;li&gt;Repeat the above 999 times&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The above can be decomposed into separate functions - one to generate a simulated dataset, one to retrieve the bootstrap statistics of interest and one to contain these two, which we will call from a loop with 999 iterations.&lt;/p&gt;

&lt;h3 id=&#34;data-generation&#34;&gt;Data Generation&lt;/h3&gt;

&lt;p&gt;This first function creates a dataset representative of the data we might observe in our real experiment. Each time the method is called a new data set will be created. Ignore the single nucleotide polymorphisms (&lt;a href=&#34;https://en.wikipedia.org/wiki/Single-nucleotide_polymorphism&#34; target=&#34;_blank&#34;&gt;SNP&lt;/a&gt;) variables for now.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;get.data &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;(n.arm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;325&lt;/span&gt;, 
                     p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.174&lt;/span&gt;,
                     or.trt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5329&lt;/span&gt;,
                     or.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;, 
                     include.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; F){

  &lt;span style=&#34;color:#75715e&#34;&gt;# We create a linear predictor from which we generate data.&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# y ~ b0 + b1 * grp&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# or &lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# y ~ b0 + b1 * grp + b2 * snp&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# The response of interest is asthma, denoted as 1/0 (yes/no).&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# Assume proportion in the ctl group with asthma is 0.174.&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# So, assuming the control group is the referant, &lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# the baseline odds are:&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# p / (1-p) = 0.210653753&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# Taking the log of this gives us the intercept term&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# log(0.21) = -1.55754&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# The OR for intervention is 0.5329:&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# log(0.5329) = -0.6294215&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;# Baseline odds:&lt;/span&gt;
  b0 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;log&lt;/span&gt;(p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; p.ctl))
  &lt;span style=&#34;color:#75715e&#34;&gt;# b1 is the coef for trt effect&lt;/span&gt;
  b1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;log&lt;/span&gt;(or.trt)
   
  &lt;span style=&#34;color:#75715e&#34;&gt;# Group membership (0 = ctl, 1 = trt arm)&lt;/span&gt;
  grp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n.arm), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n.arm))
  
  snp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;NA&lt;/span&gt;
  
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (include.snp){
    b2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;log&lt;/span&gt;(or.snp)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Genetic disposition to asthmatic kids in 86% of the population.&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# The 86% is arbitrary and made up just for the example.&lt;/span&gt;
    snp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; rbinom(n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;n.arm, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.86&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Linear predictor a combination of group and genetic disposition&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# for having an asthmatic kid&lt;/span&gt;
    logit.y &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; b0 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b1 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b2 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; snp
  } &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; {
    &lt;span style=&#34;color:#75715e&#34;&gt;# Linear predictor for the simple group comparison&lt;/span&gt;
    logit.y &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; b0 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b1 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; grp 
  }

  &lt;span style=&#34;color:#75715e&#34;&gt;# Gives us a randomly generated sequence of asthmatic kids&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# based on individual probability of event.&lt;/span&gt;
  p.y &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;exp&lt;/span&gt;(logit.y)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;exp&lt;/span&gt;(logit.y))
  y &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; rbinom(n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;n.arm, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.y)
  
  &lt;span style=&#34;color:#75715e&#34;&gt;# Our pseudo sample.&lt;/span&gt;
  df.dat &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;length&lt;/span&gt;(grp), 
                       grp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; grp, 
                       snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; snp,
                       p.y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.y,
                       y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y)
  
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;(df.dat)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;bootstrap-function&#34;&gt;Bootstrap Function&lt;/h3&gt;

&lt;p&gt;This function is used by the call to the &lt;code&gt;boot&lt;/code&gt; function - more context can be found in the R help section for &lt;code&gt;boot&lt;/code&gt;. Given a dataset and indices the function fits a GLM using a supplied formula/specification and returns estimates and predictions from the fitted model.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Boot strapped logistic giving diff between proportions&lt;/span&gt;
boot.glm &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;(df.b, 
                     indices, 
                     myformula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; myformula,
                     df.new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.new) {
  
  &lt;span style=&#34;color:#75715e&#34;&gt;# GLM Logistic&lt;/span&gt;
  d &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.b[indices, ]
  m &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; glm(myformula, family&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;binomial, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; d)
  
  prop &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; predict(m, newdata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.new, type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;response&amp;#34;&lt;/span&gt;)
  p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; prop[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
  p.trt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; prop[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
  p.diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; p.trt
  est.or &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;exp&lt;/span&gt;(coef(m))[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]

  &lt;span style=&#34;color:#75715e&#34;&gt;# s &amp;lt;- summary(m)&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# est.or.pval &amp;lt;- s$coefficients[&amp;#34;stageint.2&amp;#34;, &amp;#34;Pr(&amp;gt;|z|)&amp;#34;]&lt;/span&gt;

  &lt;span style=&#34;color:#66d9ef&#34;&gt;as.numeric&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.ctl,
               p.trt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.trt,
               p.diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.diff,
               est.or &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; est.or))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;simulation-function&#34;&gt;Simulation Function&lt;/h3&gt;

&lt;p&gt;This function encapsulates the code required to perform a single iteration of the simulation. It calls on the &lt;code&gt;get.data&lt;/code&gt; described earlier then bootstraps a GLM model (with a pre-specified formula) to obtain parameter estimates and confidence intervals and dumps them into a data.frame that is returned to the calling function.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;sim.glm &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;(x,
                    n.arm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;325&lt;/span&gt;, 
                    p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.174&lt;/span&gt;,
                    or.trt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5329&lt;/span&gt;,
                    or.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;, 
                    boot.reps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;,
                    include.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; F){
  
  
  df.dat &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get.data(n.arm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n.arm, 
                     p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.ctl,
                     or.trt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; or.trt,
                     or.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; or.snp, 
                     include.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; include.snp)


  &lt;span style=&#34;color:#75715e&#34;&gt;# Specify the required formula to fit&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;(include.snp){
    myformula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; snp
    df.new &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(grp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  }&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;{
    myformula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; grp
    df.new &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(grp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
  }

  &lt;span style=&#34;color:#75715e&#34;&gt;# Bootstrap&lt;/span&gt;
  bb &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; boot&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;boot(df.dat, 
                   statistic&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;boot.glm, 
                   R&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;boot.reps, 
                   myformula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; myformula, 
                   df.new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.new)
  

  &lt;span style=&#34;color:#75715e&#34;&gt;# First look at differences&lt;/span&gt;
  glm.prob.diff.est &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;mean&lt;/span&gt;(bb&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;t&lt;/span&gt;[,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
  glm.prob.diff.lwr &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as.numeric&lt;/span&gt;(quantile(bb&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;t&lt;/span&gt;[,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], probs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.025&lt;/span&gt;))
  glm.prob.diff.upr &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as.numeric&lt;/span&gt;(quantile(bb&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;t&lt;/span&gt;[,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], probs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.975&lt;/span&gt;))
  glm.prob.sig.diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ifelse&lt;/span&gt;(glm.prob.diff.est &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; glm.prob.diff.lwr &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
  
  &lt;span style=&#34;color:#75715e&#34;&gt;# Now look at OR&lt;/span&gt;
  glm.or.est &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;mean&lt;/span&gt;(bb&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;t&lt;/span&gt;[,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])

  
  &lt;span style=&#34;color:#75715e&#34;&gt;# Note that for the snp tests, the probability of having an asthmatic kid&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# is conditional on presence of snp.&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;(include.snp){
    &lt;span style=&#34;color:#75715e&#34;&gt;# names(df.dat)&lt;/span&gt;
    df.tmp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.dat[df.dat&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;grp&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; df.dat&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;snp&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, ] 
    n.pre &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.tmp)
    p.pre &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;(df.tmp&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;y)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.tmp)
    
    df.tmp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.dat[df.dat&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;grp&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; df.dat&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;snp&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, ] 
    n.post &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.tmp)
    p.post &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;(df.tmp&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;y)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.tmp)
  }&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;{
    n.pre &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.dat)
    p.pre &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;(df.dat&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;y)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.dat)
    
    n.post &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.dat)
    p.post &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;(df.dat&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;y)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.dat)
  }

  
  df.simres &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(n.pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n.pre,
                          n.post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n.post,
                          p.pre &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.pre,
                          p.post &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.post,
                          glm.prob.diff.est &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glm.prob.diff.est,
                          glm.prob.diff.lwr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glm.prob.diff.lwr,
                          glm.prob.diff.upr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glm.prob.diff.upr,
                          glm.prob.sig.diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glm.prob.sig.diff, 
                          glm.or.est &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glm.or.est,
                          simid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x)

  df.simres
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;bringing-it-together&#34;&gt;Bringing it together&lt;/h3&gt;

&lt;p&gt;Here we incorporate the functions into a &lt;a href=&#34;https://en.wikipedia.org/wiki/Monte_Carlo_method&#34; target=&#34;_blank&#34;&gt;monte carlo simulation&lt;/a&gt;. We initialise variables and then start a loop using parallel processing (to reduce run time if multiple cores are available). The results from each simulation is stored in the &lt;code&gt;df.out2&lt;/code&gt; &lt;code&gt;data.frame&lt;/code&gt;. We can interogate &lt;code&gt;df.out2&lt;/code&gt; to get insight into the distribution of various estimates of interest.&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Initialise variables&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;set.seed&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;354&lt;/span&gt;)
nsim &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;999&lt;/span&gt;
n.arm &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;650&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# c(500, 550, 600, 650, 700)&lt;/span&gt;
p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.174&lt;/span&gt;
or.trt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5329&lt;/span&gt;
or.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;
boot.reps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;299&lt;/span&gt;
include.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; F

&lt;span style=&#34;color:#75715e&#34;&gt;# Run the analysis in parallel across multiple CPU cores&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Initiate cluster&lt;/span&gt;
no_cores &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; detectCores() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
cl &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; makeCluster(no_cores)

&lt;span style=&#34;color:#75715e&#34;&gt;# Specify all the functions that are required by the sim.&lt;/span&gt;
clusterExport(cl&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cl, &lt;span style=&#34;color:#66d9ef&#34;&gt;list&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;get.data&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;boot.glm&amp;#34;&lt;/span&gt;))

l.res2 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; parLapply(cl, 
                    &lt;span style=&#34;color:#66d9ef&#34;&gt;seq&lt;/span&gt;(nsim), 
                    fun &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sim.glm, 
                    n.arm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n.arm, 
                    p.ctl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.ctl,
                    or.trt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; or.trt,
                    or.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; or.snp,
                    boot.reps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; boot.reps,
                    include.snp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; include.snp)

stopCluster(cl)


df.out2 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as.data.frame&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;do.call&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rbind&lt;/span&gt;, l.res2))
&lt;span style=&#34;color:#66d9ef&#34;&gt;mean&lt;/span&gt;(df.out2&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;glm.prob.sig.diff)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;By setting the &lt;code&gt;include.snp&lt;/code&gt; variable to &lt;code&gt;TRUE&lt;/code&gt; we can run a second analysis using the same code that introduces a SNP covariate into the data generation process and the GLM specification to see what effect it has on power.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;The figure below shows the probability density for the lower bound of the difference in proportions of children born with asthma in each group. The central values for each group were 0.1 and 0.174 for the treatment and control groups respectively, aligning with the prespecified values. The proportion of the simulations where the &lt;strong&gt;lower bound&lt;/strong&gt; of a 95% confidence interval for each of the estimated differences is greater than zero is 0.76, i.e. a little under 80%.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/power01-diff01.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Important Note: We are looking at the difference in predicted proportions with asthma. We would get a different result if we were just looking at the significance of the odds ratio estimated from the GLM.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The next figure shows the same plot obtained from the analysis stratified by the SNP status. In this case the proportion of the simulations where the &lt;strong&gt;lower bound&lt;/strong&gt; of a 95% confidence interval for each of the estimated differences is greater than zero is 0.87 giving 87% power.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/power01-diff02.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;By introducing a patient characteristic that was related to the response we were able to increase power without adjusting the sample size assumptions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Interpreting Interaction Terms in a GLM (Binomial family, log link) - Logistic Regression</title>
      <link>https://t-student.github.io/post/logistic01-interaction/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +1100</pubDate>
      
      <guid>https://t-student.github.io/post/logistic01-interaction/</guid>
      <description>&lt;p&gt;The following code simulates events (deaths) from a known model for two groups over three time points. We adopt the view that the effects of time are linear. So, we have deaths acorss two groups (0 = control, 1 = treatment) at three time points (0 = baseline, 1 = 1 year in, 2 = 2 years in). We pre-specify a linear predictor relating group membership and timepoint to the probability of death and then generate bernouli trials based on these probabilities.&lt;/p&gt;

&lt;p&gt;The logistic regression model that we consider is:&lt;/p&gt;

&lt;p&gt;$$
log Pr(Y = 1) = \beta_0 + \beta_1 grp + \beta_2 time + \beta_3 grp \times time
$$&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;set.seed&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Define the parameters&lt;/span&gt;
b0 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;
b1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-0.1&lt;/span&gt;
b2 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;
b3 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-0.3&lt;/span&gt;

n &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1200&lt;/span&gt;
grp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))

&lt;span style=&#34;color:#75715e&#34;&gt;# Model for the means&lt;/span&gt;
p &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; b0 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b1 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b2 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; time &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b3 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; time

df.fig &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(grp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; grp, time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p)
df.fig&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;y &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; rbinom(n, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, p)

&lt;span style=&#34;color:#75715e&#34;&gt;# The probability of death&lt;/span&gt;
ggplot(df.fig, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;factor&lt;/span&gt;(grp))) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_point()&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_line()&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  scale_x_continuous(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Timepoint&amp;#34;&lt;/span&gt;, breaks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  scale_y_continuous(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Proportion Death&amp;#34;&lt;/span&gt;, breaks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;seq&lt;/span&gt;(from &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, to &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, length.out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;))

&lt;span style=&#34;color:#75715e&#34;&gt;# Proportion of deaths observed in the simulated data&lt;/span&gt;
df.tmp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.fig &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;group_by(grp, time) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;summarise(p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;(y)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;n())

&lt;span style=&#34;color:#75715e&#34;&gt;# The Simulated data&lt;/span&gt;
ggplot(df.fig, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;factor&lt;/span&gt;(grp))) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_jitter(height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_point(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.tmp, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;factor&lt;/span&gt;(grp)))&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_line(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.tmp, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;factor&lt;/span&gt;(grp)))&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  scale_x_continuous(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Timepoint&amp;#34;&lt;/span&gt;, breaks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  scale_y_continuous(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Died&amp;#34;&lt;/span&gt;, breaks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, 
                     sec.axis &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sec_axis(&lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.&lt;/span&gt;, 
                                         name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Proportion Death&amp;#34;&lt;/span&gt;,
                                         breaks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;seq&lt;/span&gt;(from &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, to &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, length.out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The probabilities and simulated data are shown below:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Means (p parameter)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Simulated data&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/logit01-interactionfig1.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/logit01-interactionfig2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we fit a logistic regression model to the simulated data using the following commands:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(lm1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; glm(y &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; time, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.fig, family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; binomial()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;exp&lt;/span&gt;(coef(lm1))

predict(lm1, type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;response&amp;#34;&lt;/span&gt;, newdata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(grp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), 
                                                     time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;which gives us parameter estimates and predicted values as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Coefficients:
            Estimate Std. Error z value Pr(&amp;gt;|z|)    
(Intercept)  -0.4331     0.1333  -3.248  0.00116 ** 
grp          -0.2935     0.1949  -1.506  0.13210    
time          0.9363     0.1144   8.188 2.65e-16 ***
grp:time     -1.6395     0.1757  -9.333  &amp;lt; 2e-16 ***

exp(coef(lm1))
(Intercept)         grp        time    grp:time 
  0.6485035   0.7456175   2.5506104   0.1940778 

predict(lm1, type = &amp;quot;response&amp;quot;, newdata = data.frame(grp = c(0, 0, 0, 1, 1, 1), time = c(0, 1, 2, 0, 1, 2)))
        1         2         3         4         5         6 
0.3933892 0.6232216 0.8083892 0.3259346 0.1931308 0.1059346 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The exponentiated intercept term represents the baseline odds of death. Similarly, the exponentiated group and time main effects are odds-ratios. However, the exponentiated interaction term is a ratio of odds-ratios.&lt;/p&gt;

&lt;p&gt;The baseline odds are $exp(-0.4331) = 0.6485$. I have a terrible time thinking in odds (mainly because they are unbounded to the right) so I always convert to probabilities. The baseline odds of death equate to $odds/(1+odds) = 0.393$. This aligns with the &lt;code&gt;b0&lt;/code&gt; parameter in the linear predictor so things look good.&lt;/p&gt;

&lt;p&gt;While the main effect for suggests that the treatment group have lower odds of death at baseline, the effect is not significant at the 0.05 level. Nevertheless we know that the probability of death diverges over time and the interaction term is clearly significant so the main effect is usually retained in the model. The result suggests that the odds of death at baseline are a factor of $exp(-0.2935) = 0.746$ lower in the treatment group compared to the control group, i.e. 0.6485 \times 0.746 = 0.484$. In probabilities this implies that the probability of death at baseline in the treatment group is 0.326.&lt;/p&gt;

&lt;p&gt;In the control group we expect an increase in the odds of death by a factor of $exp(0.94) = 2.55$ for every unit increase in time. For example, at the first timepoint we expect the odds of death in the control group to be the baseline odds multiplied by 2.55, which is 1.654. This equates to a probability of death equal to 0.62, which aligns approximately with our pre-specified probability of 0.6 (and the predicted values from the code above). Similarly, at the second time point we expect that the odds of death in the control group is a whopping $exp(-0.43 + 2 \times 0.936) = 4.22, again correctly equating to the pre-specified probability of death of 0.808.&lt;/p&gt;

&lt;p&gt;The interpretation of the interaction term becomes clear when considering the expected probability of death over time. First we note that in the first timepoint, the odds of death in the treatment group are $exp(-0.43-0.29+0.94-1.64) = 0.24$ equating to a probability of 0.1931. As we saw before, the odds ratio for time in the control group is $exp(0.936) = 2.55$. Similarly the OR for time in the treatment group is $exp(0.9363 + -1.6395) = 0.495$. The ratio of these two values is $0.495 / 2.55 = 0.194$ which equates to the exponentiated interaction term.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Interpreting Interaction Terms in a GLM (Poisson family, log link)</title>
      <link>https://t-student.github.io/post/poisson01-interaction/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +1100</pubDate>
      
      <guid>https://t-student.github.io/post/poisson01-interaction/</guid>
      <description>&lt;p&gt;The following code constructs a hypothetical dataset describing the count of events observed in two groups (0 = control, 1 = treatment) at two times (0 = baseline, 1 = follow up) with means defined through a pre-specified model.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;set.seed&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Define the parameters&lt;/span&gt;
b0 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
b1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
b2 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;
b3 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;

n &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;800&lt;/span&gt;
grp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
&lt;span style=&#34;color:#75715e&#34;&gt;# Model for the means&lt;/span&gt;
lambda &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; b0 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b1 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b2 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; time &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b3 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; time

df.fig &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(grp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; grp, time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, lambda &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lambda)
&lt;span style=&#34;color:#75715e&#34;&gt;# Generate poisson counts based on our means&lt;/span&gt;
df.fig&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;y &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; rpois(n, lambda)

&lt;span style=&#34;color:#75715e&#34;&gt;# The means&lt;/span&gt;
ggplot(df.fig, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lambda, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;factor&lt;/span&gt;(grp))) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_jitter(height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# The observed data&lt;/span&gt;
ggplot(df.fig, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;factor&lt;/span&gt;(grp))) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_jitter(height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The means and simulated data are below:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Means (lambda parameter)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Simulated data&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/poisson01-interactionfig1.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/poisson01-interactionfig2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we fit a poisson regression model to the simulated data using the following commands:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(lm1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; glm(y &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; time, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.fig, family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poisson()))
&lt;span style=&#34;color:#66d9ef&#34;&gt;exp&lt;/span&gt;(coef(lm1))

predict(lm1, type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;response&amp;#34;&lt;/span&gt;, newdata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(grp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), 
                                                     time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;which gives us parameter estimates and predicted values as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Coefficients:
            Estimate Std. Error z value Pr(&amp;gt;|z|)    
(Intercept)  0.67039    0.05057  13.256  &amp;lt; 2e-16 ***
grp          0.94404    0.05960  15.839  &amp;lt; 2e-16 ***
time         0.56071    0.06338   8.846  &amp;lt; 2e-16 ***
grp:time     0.38325    0.07348   5.216 1.83e-07 ***

exp(coef(lm1))
(Intercept)         grp        time    grp:time 
   1.955000    2.570332    1.751918    1.467049 

predict(lm1, type = &amp;quot;response&amp;quot;, newdata = data.frame(grp = c(0, 0, 1, 1), time = c(0, 1, 0, 1)))
     1      2      3      4 
 1.955  3.425  5.025 12.915 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The exponentiated intercept, group and time parameters align with what we expect based on the model we specified. However, the interaction term is 1.50 which clearly does not equal 6. What is going on? The answer, in a word, is that the exponentiated parameter estimates are interpreted multiplicatively. We can find the correct interpretation through some simple calculations.&lt;/p&gt;

&lt;p&gt;At baseline the model indicates that we expect to see $exp(0.67) = 1.96$ events in the control cohort whereas we expect to see $exp(0.67)exp(0.94) = 5.0$ events in the treatment cohort. Both these values are close to the means we specified, namely 2 and 5.&lt;/p&gt;

&lt;p&gt;Similarly, at follow up the fitted value for the control group is $exp(0.67)exp(0.56) = 3.4$. Now, if the treatment were no different from the control intervention then we would expect to see something like $exp(0.67)exp(0.94)exp(0.56) = 8.80$ events at follow up. But this isn&amp;rsquo;t the case &amp;ndash; the model says we expect to see $8.76 \times exp(0.38) = 12.92$ events. Thus, the exponentiated &lt;code&gt;grp:time&lt;/code&gt; parameter suggests that we expect to see a $exp(0.38) = 1.47$ (or approx. 150%) increase &lt;em&gt;ABOVE&lt;/em&gt; the change observed in the control group at follow up. Additionally, it is also worth to note that the interpretation is in terms of what we think the means look like there is no direct link back to our pre-specified parameters. If you do want to sanity check and recover estimates of the original parameters then you can specify the identity link as follows:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(lm1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; glm(y &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; grp &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; time, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.fig, family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poisson(link &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;identity&amp;#34;&lt;/span&gt;)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Coefficients:
            Estimate Std. Error z value Pr(&amp;gt;|z|)    
(Intercept)  1.95500    0.09887  19.774   &amp;lt;2e-16 ***
grp          3.07000    0.18682  16.433   &amp;lt;2e-16 ***
time         1.47000    0.16401   8.963   &amp;lt;2e-16 ***
grp:time     6.42000    0.34147  18.801   &amp;lt;2e-16 ***
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Simulating Lung Cancer Incidence data in R</title>
      <link>https://t-student.github.io/post/data01-cancer/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +1100</pubDate>
      
      <guid>https://t-student.github.io/post/data01-cancer/</guid>
      <description>

&lt;p&gt;The world is now awash in data, but sometimes it is useful to roll your own. For example, you may to look at &amp;lsquo;what if&amp;rsquo; scenarios. Here I use publically available information on the age-class-distribution, rates of smoking and incidence of smoking to form a dataset that we will use in a later modelling exercise. In order to do this I use the &lt;code&gt;simstudy&lt;/code&gt; and &lt;code&gt;data.table&lt;/code&gt; R packages.&lt;/p&gt;

&lt;h1 id=&#34;distribution-of-lung-cancer-incidence-in-australia&#34;&gt;Distribution of lung cancer incidence in Australia&lt;/h1&gt;

&lt;p&gt;The Australian Institute of Health and Welfare publish incidence and mortality data. Data by cancer type is provided &lt;a href=&#34;https://www.aihw.gov.au/reports/cancer/acim-books/contents/acim-books&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. I downloaded the lung-cancer file, which originally looked like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/data01-cancer1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I copied the 2014 data for the males and females into a new spreadsheet and loaded it into R.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;library&lt;/span&gt;(data.table)
&lt;span style=&#34;color:#f92672&#34;&gt;library&lt;/span&gt;(readxl)

&lt;span style=&#34;color:#75715e&#34;&gt;# see https://www.aihw.gov.au/reports/cancer/acim-books/contents/acim-books&lt;/span&gt;
dt.rates &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; data.table(readxl&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;read_excel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rates.xlsx&amp;#34;&lt;/span&gt;), key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex,age.bin&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;head&lt;/span&gt;(dt.rates)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre&gt;&lt;code&gt;   sex age.bin rate.per.100k
1:   f       0    0.19356413
2:   f       5    0.02926882
3:   f      10    0.16013852
4:   f      15    0.29336471
5:   f      20    0.57427154
6:   f      25    0.54157117
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Table 6 from the data cube on Australian Demographics published by the ABS and found &lt;a href=&#34;http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/3101.0Jun%202017?OpenDocument&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; gives the age class distribution by sex in Australia as at the end of 2017. Again, I copied the data I needed and ditched the rest.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;dt.ages &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; data.table(readxl&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;read_excel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rates.xlsx&amp;#34;&lt;/span&gt;), key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex,age.bin&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;head&lt;/span&gt;(dt.ages)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The age distribution across sex is similar with females living very slightly longer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/data01-agedist.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/3101.0Jun%202017?OpenDocument&lt;/span&gt;
dt.ages &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; data.table(readxl&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;read_excel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ageclass.xlsx&amp;#34;&lt;/span&gt;), key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex,age.bin&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;head&lt;/span&gt;(dt.ages)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now I use the &lt;a href=&#34;https://cran.r-project.org/web/packages/simstudy/index.html&#34; target=&#34;_blank&#34;&gt;simstudy&lt;/a&gt; package to generate some new data. I assume that males and females are distributed 50:50 within the population. I only try to get an approximate&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Set the seed for reproducibility&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;set.seed&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;345&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Create a definition for males and a separate one for females. &lt;/span&gt;
def &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; defData(varname &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex&amp;#34;&lt;/span&gt;, dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nonrandom&amp;#34;&lt;/span&gt;, formula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
def &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; defData(def, varname &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;age.bin.idx&amp;#34;&lt;/span&gt;, 
               formula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;paste0&lt;/span&gt;(dt.ages&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prop[dt.ages&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;sex &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;m&amp;#34;&lt;/span&gt;],  collapse &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;;&amp;#34;&lt;/span&gt;), 
               dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;)

n.pop &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50000&lt;/span&gt;
dtm &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; genData(n.pop, def)

def &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; defData(varname &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex&amp;#34;&lt;/span&gt;, dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nonrandom&amp;#34;&lt;/span&gt;, formula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
def &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; defData(def, varname &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;age.bin.idx&amp;#34;&lt;/span&gt;, 
               formula &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;paste0&lt;/span&gt;(dt.ages&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prop[dt.ages&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;sex &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;f&amp;#34;&lt;/span&gt;],  collapse &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;;&amp;#34;&lt;/span&gt;), 
               dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;categorical&amp;#34;&lt;/span&gt;)
n.pop &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50000&lt;/span&gt;
dtf &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; genData(n.pop, def)

&lt;span style=&#34;color:#75715e&#34;&gt;# Our working data set:&lt;/span&gt;
dt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;rbind&lt;/span&gt;(dtm, dtf)
dt&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;id &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(dt)

&lt;span style=&#34;color:#75715e&#34;&gt;# Replace the sex var with something more readable&lt;/span&gt;
dt[, sex &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ifelse&lt;/span&gt;(dt[,sex] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;m&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;f&amp;#34;&lt;/span&gt;)]
dt[, age.bin &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; (age.bin.idx&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# For each age bin, which was modelled on the APS proportion of age&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# class data, assign a random age between the start and end of age bin &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# interval. Use a random uniform distribution.&lt;/span&gt;
dt[, age &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; runif(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, age.bin, age.bin &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4.999&lt;/span&gt;), by &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; id]

&lt;span style=&#34;color:#75715e&#34;&gt;# Create an indicator for greater than age 18 to differentially&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# assign a smoking probability.&lt;/span&gt;
dt[, age18 &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ifelse&lt;/span&gt;(dt[,age] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)]
dt[, psmk &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ifelse&lt;/span&gt;(dt[,sex] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.18&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; dt[,age18], &lt;span style=&#34;color:#ae81ff&#34;&gt;0.14&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; dt[,age18])]

&lt;span style=&#34;color:#75715e&#34;&gt;# Bernouli trial to say whether smoker or not.&lt;/span&gt;
dt[, smk &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; rbinom(&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(dt), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,  prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dt[,psmk])]
dt

&lt;span style=&#34;color:#75715e&#34;&gt;# Set key in order to making joining trivial&lt;/span&gt;
setkey(dt,sex,age.bin)

&lt;span style=&#34;color:#75715e&#34;&gt;# Left join by key&lt;/span&gt;
dt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;merge&lt;/span&gt;(dt, dt.rates, all.x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Create the &lt;/span&gt;
dt[, cancer &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; rbinom(&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(dt), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,  prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rate.per.100k&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100000&lt;/span&gt;)]
dt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The end result looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       sex age.bin    id age.bin.idx        age age18 psmk smk rate.per.100k cancer
     1:   f       0 50003           1  1.9907349     0 0.00   0     0.1935641      0
     2:   f       0 50036           1  4.8925030     0 0.00   0     0.1935641      0
     3:   f       0 50043           1  0.9762412     0 0.00   0     0.1935641      0
     4:   f       0 50046           1  3.8317576     0 0.00   0     0.1935641      0
     5:   f       0 50048           1  3.4270826     0 0.00   0     0.1935641      0
    ---                                                                             
 99996:   m      85 49289          18 89.3857581     1 0.14   0   450.0924556      0
 99997:   m      85 49326          18 86.2884594     1 0.14   0   450.0924556      0
 99998:   m      85 49330          18 89.6440606     1 0.14   1   450.0924556      0
 99999:   m      85 49373          18 88.3372412     1 0.14   0   450.0924556      0
100000:   m      85 49928          18 86.4949185     1 0.14   0   450.0924556      0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As a very quick and dirty sanity check (always do a sanity check of some kind) we can compare the number of cancer cases in our simulated data with the rates we obtained earlier by scaling up each sex by age bin group. For example:&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Sanity&lt;/span&gt;
df.san &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; as_data_frame(dt) 
df.tmp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.san &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;group_by(sex, age.bin) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;summarise(scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100000&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n())
  
df.san &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.san &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;filter(cancer &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;group_by(sex, age.bin) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;summarise(sim.n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n()) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;ungroup() &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;left_join(&lt;span style=&#34;color:#ae81ff&#34;&gt;.&lt;/span&gt;, df.tmp, by &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;age.bin&amp;#34;&lt;/span&gt;)) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;mutate(sim.n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sim.n &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;scale&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;select(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;scale&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;left_join(&lt;span style=&#34;color:#ae81ff&#34;&gt;.&lt;/span&gt;, dt.rates, by &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;age.bin&amp;#34;&lt;/span&gt;)) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
  tidyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;gather(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;var&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;sex, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;age.bin)
&lt;span style=&#34;color:#75715e&#34;&gt;#&lt;/span&gt;

ggplot(df.san) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_point(aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; age.bin, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sim.n), size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_point(aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; age.bin, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rate.per.100k), 
             size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blue&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  facet_grid(&lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;sex)

&lt;span style=&#34;color:#75715e&#34;&gt;#&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;This gives the following plot, which suggests that we have constructed something similar to the predicted cancer rates stratified by sex and age group although the older ages in the male group appear to diverge somewhat.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://t-student.github.io/media/data01-simres.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Next we will use this data to do some modelling and explore coverage probabilities in logistic regression.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A brms implementation of the analysis presented in &#34;Bayesian linear mixed models using Stan: A tutorial for psychologists, linguists, and cognitive scientists&#34;</title>
      <link>https://t-student.github.io/post/brms01/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +1100</pubDate>
      
      <guid>https://t-student.github.io/post/brms01/</guid>
      <description>

&lt;p&gt;The title was stolen directly from the excellent 2016 &lt;a href=&#34;https://arxiv.org/abs/1506.06201&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; by Tanner Sorensen and Shravan Vasishth. Here I recreate their analysis using &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/index.html&#34; target=&#34;_blank&#34;&gt;brms&lt;/a&gt; R package, primarily as a self-teach exercise. I am going to very much assume that the basic ideas of Bayesian analysis are already understood. I will add some informtion on prior and posterior predictive checks because I think not doing so missing a large part of the point of a Bayesian analysis. The original tutorial provided a hands-on introduction to fitting LMMs in a Bayesian framework using the probabilistic programming language &lt;a href=&#34;http://mc-stan.org/&#34; target=&#34;_blank&#34;&gt;Stan&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with the data. In brief the we have reading times (&lt;code&gt;rt&lt;/code&gt;) in milliseconds of the head noun of the relative clause recorded in two conditions with 37 subjects and 15 items. The data have some missing values, but the focus here was on a complete case analysis because missing values are a can of worms in Stan and deserve a tutorial of their own. In total we are looking at 547 data points.&lt;/p&gt;

&lt;p&gt;Quoting Sorensen:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;subject relative&lt;/strong&gt; is a sentence like &lt;em&gt;&amp;ldquo;The senator who interrogated the journalist resigned&amp;rdquo;&lt;/em&gt; where a noun (senator) is modified by a relative clause (who interrogated the journalist), and the modified noun is the grammatical subject of the relative clause. In an &lt;strong&gt;object relative&lt;/strong&gt;, the noun modified by the relative clause is the grammatical object of the relative clause like &lt;em&gt;&amp;ldquo;The senator who the journalist interrogated resigned&amp;rdquo;&lt;/em&gt;. In both cases, the noun that is modified (senator) is called the head noun.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can pick up what you need &lt;a href=&#34;https://github.com/vasishth/BayesLMMTutorial/blob/master/data/gibsonwu2012data.txt&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and save it to a local folder, but you can also read that file directly.  We only need a part of the data so lets wrap it up in a function.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;library&lt;/span&gt;(tidyverse)
&lt;span style=&#34;color:#f92672&#34;&gt;library&lt;/span&gt;(brms)

get.data &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;(){
  df.r &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; read.table(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://raw.githubusercontent.com/vasishth/BayesLMMTutorial/master/data/gibsonwu2012data.txt&amp;#39;&lt;/span&gt;)  
  &lt;span style=&#34;color:#75715e&#34;&gt;# head(df.r)&lt;/span&gt;
  
  df.r &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.r &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
    dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;filter(region &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;headnoun&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
    dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;select(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;word) &lt;span style=&#34;color:#f92672&#34;&gt;%&amp;gt;%&lt;/span&gt;
    dplyr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;mutate(subj &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as.factor&lt;/span&gt;(subj),
                  item &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as.factor&lt;/span&gt;(item),
                  so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ifelse&lt;/span&gt;(type &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;subj-ext&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)) 
  &lt;span style=&#34;color:#75715e&#34;&gt;# head(df.r)&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# sort(as.numeric(unique(df.r$subj)))&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# sort(as.numeric(unique(df.r$item)))&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;# nrow(df.r)&lt;/span&gt;
  
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;(df.r)
}


df.r &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get.data()

&lt;span style=&#34;color:#75715e&#34;&gt;# Distribution of reading times. &lt;/span&gt;
plot(density(df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;rt), main &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Distribution of reading times&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above code you will note that the &lt;code&gt;so&lt;/code&gt; variable contains an indicator of &amp;lsquo;o&amp;rsquo; (object relative) and &amp;rsquo;s&amp;rsquo; (subject relative) that are coded as 1 and -1 respectively. When coding up Stan models you need to be a bit more careful with your data &amp;ndash; we might come back to this later.&lt;/p&gt;

&lt;!-- A quick look at the reading times shows us what we expect to see, namely a heavily skewed distribution. 

&lt;figure &gt;
    
        &lt;img src=&#34;https://t-student.github.io/media/brms-tutorial-01.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;PDF of reading times&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;
 --&gt;

&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/index.html&#34; target=&#34;_blank&#34;&gt;brms&lt;/a&gt; package supports a wide range of (non-)linear multivariate multilevel models using Stan for full Bayesian inference. Many distributional assumptions are supported. Additionally, brms provides the capability of extracting the underlying Stan code and thus gives a useful starting point if you want to do something more complicated. As a starting point we ignore the (very likely) possibility of correlated measures and fit a fixed effect model. We use weakly informative priors, but not the current &lt;code&gt;stan-dev&lt;/code&gt; &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34; target=&#34;_blank&#34;&gt;reccommendations&lt;/a&gt; nor a Cauchy&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; distribution as per Gelman et al. 2008 &lt;a href=&#34;https://arxiv.org/pdf/0901.4011.pdf&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;. Here, we adopt Normal priors, simply because they are easy to think about and rationalise. For reference, the parameterisations of the brms supported distributions can be found &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;an-initial-model&#34;&gt;An Initial Model&lt;/h2&gt;

&lt;p&gt;Prior to looking at the data, what do we know about average reading speed? Well, obviously, the lower bound is a little be greater than zero and a high value might be a couple of seconds. So, lets just say a typcial value is about 1000 millisecs and you could expect anywhere between about 100 and 2000 milliseconds and that gives us some guidance on what the intercept looks like. We are pulling numbers out of the air here, but at least we have a rough idea of what the typical value might be and we can (should) conduct sensitivity analyses with uninformative priors (that typically correspond with frequentist results).&lt;/p&gt;

&lt;p&gt;$$ rt_i \sim Lognormal(\mu_i, \sigma) \\\ \mu_i = \beta_0 + \beta_1 so_i \\\  \beta_0 \sim Normal(6, 1) \\\  \beta_1 \sim Normal(0, 10) \\\  \sigma \sim Student-t(3, 0, 10) $$&lt;/p&gt;

&lt;p&gt;OK, let&amp;rsquo;s fit a model. The brms package can have multi-dimensional formula so we specify the formula explicitly as &lt;code&gt;myf&lt;/code&gt; and use this approach repeatedly.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# brms formula, more later...&lt;/span&gt;
myf &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; bf(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so)
priors &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get_prior(myf,
                    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
                    family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal())
priors&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prior[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal(0, 10)&amp;#34;&lt;/span&gt;
priors&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prior[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal(6, 1)&amp;#34;&lt;/span&gt;
priors

blm0 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; brms&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;brm(myf, 
            data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
            family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal(),
            prior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; priors,
            control &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;list&lt;/span&gt;(max_treedepth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;),
            iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;,
            chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, cores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, seed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5453&lt;/span&gt;, save_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;brm1.txt&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(blm0, waic &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;blm0&lt;/code&gt; is an instance of a &lt;code&gt;brmsfit&lt;/code&gt; object. The &lt;code&gt;summary&lt;/code&gt; view gives the following output, which is similar to the fixed effects model presented by Sorensen. What are these results telling us? First, the Rhat values are equal to 1, so the chains look like they converged OK. Second, the reading time for subject-relative has a central value around $exp(6.06 + 0.04) = 446$ millisecs and the object-relative has a central value of around $exp(6.06 - 0.04) = 412$ millisecs. These values align to the exponentiated mean of the log reading times for the two groups.&lt;/p&gt;

&lt;!--We expect typical values to be $exp(2 \times 0.6) = 3.3$ --&gt;

&lt;pre&gt;&lt;code&gt; Family: lognormal 
  Links: mu = identity; sigma = identity 
Formula: rt ~ so 
   Data: df.r (Number of observations: 547) 
Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1; 
         total post-warmup samples = 2000
    ICs: LOO = NA; WAIC = 7625.74; R2 = NA
 
Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
Intercept     6.06      0.03     6.01     6.11       1917 1.00
so           -0.04      0.03    -0.09     0.01       2000 1.00

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma     0.60      0.02     0.57     0.63       2000 1.00

Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
is a crude measure of effective sample size, and Rhat is the potential 
scale reduction factor on split chains (at convergence, Rhat = 1).

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The marginal posterior distributions for each of the three parameters are shown below. The distribution of &lt;code&gt;b_s0&lt;/code&gt; is mostly below zero suggesting that the object-relative is easier to read. However, the 95\% &lt;em&gt;credible interval&lt;/em&gt; includes zero so the evidence is not particularly strong. Unlike frequentist analyses, the results give us a view on the uncertainty in the error term (&lt;code&gt;sigma&lt;/code&gt;) which ranges from 0.57 to 0.63 on the log scale.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://t-student.github.io/media/brms01-posterior1.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Posterior distribution for estimated parameters&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Here&amp;rsquo;s a view of the observed data overlayed with the posterior distribution for reading times showing the estimated typical reading time. The right hand plot shows a &lt;strong&gt;posterior predictive distribution&lt;/strong&gt;, which embodies both the uncertainty inherent in our distributional assumption for the response and the uncertainty in the estimated parameters. The idea behind examining the posterior predictive distribution is that it should generate data that looks similar to the observed data. &lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34; target=&#34;_blank&#34;&gt;McElreath&lt;/a&gt; provides the clearest exposition I have read on this concept. The posterior predictive is a simulation of our original data conditional on the observed values.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Posterior means&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Posterior predictive&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/brms01-posterior2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/brms01-posterior3.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Another option for model checking is to use the &lt;a href=&#34;https://cran.r-project.org/web/packages/bayesplot/index.html&#34; target=&#34;_blank&#34;&gt;bayesplot&lt;/a&gt; package, which provides a swag-full of posterior predictive checks that are more sophisticated than the single generated dataset shown above. Below we can see that simulated data has a much lower maximum value than that observed in the original data and the median of the simulated values is actually quite a lot higher than we observed. Both these diagnostics suggest the current model does not characterise the data well.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;PPC (max)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;PPC (median)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/brms01-ppc4.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/brms01-ppc5.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Posterior predictive checks grouped by subject and object relative (see below) appear to show that the issues manifest to a greater extent in the subject relative group. An outline of the code for the last few plots is also shown below.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;PPC (max)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;PPC (median)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/brms01-ppc6.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://t-student.github.io/media/brms01-ppc7.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Look at the posterior distribution&lt;/span&gt;
m.post &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as.matrix&lt;/span&gt;(blm0)
&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(m.post)
df.post1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data_frame&lt;/span&gt;(type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;subj-ext&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;obj-ext&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;)), 
                      rt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(m.post[,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; m.post[,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], m.post[,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; m.post[,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])  )
&lt;span style=&#34;color:#66d9ef&#34;&gt;set.seed&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;324&lt;/span&gt;)
idx &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; base&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sample&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.post1), &lt;span style=&#34;color:#ae81ff&#34;&gt;600&lt;/span&gt;, replace &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; F)
df.post1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.post1[idx, ]

&lt;span style=&#34;color:#75715e&#34;&gt;# Posterior&lt;/span&gt;
ggplot(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r , aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; type, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rt))&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_jitter(width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;red&amp;#34;&lt;/span&gt;, alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_jitter(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.post1, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; type, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;exp&lt;/span&gt;(rt) ), 
              width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blue&amp;#34;&lt;/span&gt;, alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  ylab(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Reading time (millisec)&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; xlab(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;)


&lt;span style=&#34;color:#75715e&#34;&gt;# Single draw just for demonstration&lt;/span&gt;
pp.tmp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; brms&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;posterior_predict(blm0, newdata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)))
&lt;span style=&#34;color:#66d9ef&#34;&gt;dim&lt;/span&gt;(pp.tmp)

df.post2 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data_frame&lt;/span&gt;(type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;subj-ext&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;rep&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;obj-ext&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;)), 
                      rt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(pp.tmp[,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], pp.tmp[,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])  )
&lt;span style=&#34;color:#66d9ef&#34;&gt;set.seed&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;284729&lt;/span&gt;)
idx &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; base&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sample&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(df.post2), &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, replace &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; F)
df.post2 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; df.post2[idx, ]
str(df.post2)

ggplot(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r , aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; type, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rt))&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_jitter(width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;red&amp;#34;&lt;/span&gt;, alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  geom_jitter(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.post2, aes(x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; type, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rt ), 
              width &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, height &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, colour &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blue&amp;#34;&lt;/span&gt;, alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  ylab(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Reading time (millisec)&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; xlab(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;)


&lt;span style=&#34;color:#75715e&#34;&gt;# More useful PPC&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;library&lt;/span&gt;(bayesplot)
ppc_dens_overlay(df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;rt, yrep[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, ])

ppc_stat(df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;rt, yrep, stat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;max&amp;#34;&lt;/span&gt;)
ppc_stat(df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;rt, yrep, stat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;median&amp;#34;&lt;/span&gt;)

ppc_stat_grouped(df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;rt, yrep, stat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;max&amp;#34;&lt;/span&gt;, group &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;so)
ppc_stat_grouped(df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;rt, yrep, stat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;median&amp;#34;&lt;/span&gt;, group &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;so)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;relaxing-the-equal-variance-assumption&#34;&gt;Relaxing the equal variance assumption&lt;/h2&gt;

&lt;p&gt;While Sorensen do not explore this avenue, one possibility is that we may have reasonable distributional assumptions but the notion of a shared variance across groups may not be accurate. The brms package readily supports this refinement via its forumla interface that we used earlier. We do not nominate any priors for the &lt;code&gt;sigma&lt;/code&gt; model parameters so they will just be assigned uninformative defaults.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;myf &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; bf(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so, sigma &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so)
priors &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get_prior(myf,
                    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
                    family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal())
priors&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prior[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal(0, 10)&amp;#34;&lt;/span&gt;
priors&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prior[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal(6, 1)&amp;#34;&lt;/span&gt;

blm1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; brm(myf, 
            data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
            family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal(),
            prior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; priors,
            control &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;list&lt;/span&gt;(max_treedepth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;),
            iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;,
            chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, cores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, seed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5453&lt;/span&gt;, save_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;brm1.txt&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(blm1, waic &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The results (below) suggest that the variation in reading times are different across subject and object groups. However, posterior predictive checks on the maximum and median values (not shown) are still not representative of the observed values. We won&amp;rsquo;t take this further yet, but we might return to it later.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; Family: lognormal 
  Links: mu = identity; sigma = log 
Formula: rt ~ so 
         sigma ~ so
   Data: df.r (Number of observations: 547) 
Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1; 
         total post-warmup samples = 2000
    ICs: LOO = NA; WAIC = 7614.42; R2 = NA
 
Population-Level Effects: 
                Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
Intercept           6.06      0.02     6.01     6.11       1897 1.00
sigma_Intercept    -0.53      0.03    -0.58    -0.46       2000 1.00
so                 -0.04      0.03    -0.09     0.01       1768 1.00
sigma_so           -0.11      0.03    -0.17    -0.05       1892 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;modelling-the-repeat-measures&#34;&gt;Modelling the Repeat Measures&lt;/h2&gt;

&lt;p&gt;Given we know there are repeat measures in the data, we should model it as such or risk violating an assumption of independence. We do this by specifying person-level and item-level variability in the model. I won&amp;rsquo;t say most, but a lot of people refer to these as &lt;em&gt;random intercepts&lt;/em&gt;. Here is the revised model. You can see that the $\beta_{person[i]}$ and $\beta_{item[i]}$ make adjustments to the intercept term dependent on the particular person and the particular item, hence the random intercept terminology.&lt;/p&gt;

&lt;p&gt;$$ rt_i \sim Lognormal(\mu_i, \sigma) \\\ \mu_i = \beta_0 + \beta_{person[i]} + \beta_{item[i]} +  \beta_1 so_i \\\  \beta_0 \sim Normal(6, 1) \\\  \beta_{person} \sim Normal(0, \sigma_{person}) \\\ \beta_{item} \sim Normal(0, \sigma_{item}) \\\ \beta_1 \sim Normal(0, 10) \\\  \sigma, \sigma_{person} , \sigma_{item} \sim Student-t(3, 0, 10)  $$&lt;/p&gt;

&lt;p&gt;It is a straight forward exercise to ask &lt;code&gt;brms&lt;/code&gt; to fit this model. For the sake of simplicity, we will not continue to model the standard deviation across groups and I haven&amp;rsquo;t specified all the priors but it would be simple to do so.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Random effects model&lt;/span&gt;
df.r &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get.data()
myf &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; bf(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item))
priors &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get_prior(myf,
                    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
                    family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal())
priors&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prior[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal(0, 10)&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;gt; priors&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#                   prior     class      coef group resp dpar nlpar bound&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 1         normal(0, 10)         b                                      &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 2         normal(0, 10)         b        so                            &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 3 student_t(3, 5.9, 10) Intercept                                      &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 4   student_t(3, 0, 10)        sd                                      &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 5                              sd            item                      &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 6                              sd Intercept  item                      &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 7                              sd            subj                      &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 8                              sd Intercept  subj                      &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 9   student_t(3, 0, 10)     sigma                  &lt;/span&gt;


blm2 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; brm(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item), 
            data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
            family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal(),
            prior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; priors,
            control &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;list&lt;/span&gt;(max_treedepth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;),
            iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;,
            chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, cores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, seed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5453&lt;/span&gt;, save_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;brm1.stan&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(blm2)


post1 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; brms&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;posterior_predict(blm2)
&lt;span style=&#34;color:#66d9ef&#34;&gt;dim&lt;/span&gt;(post1)
&lt;span style=&#34;color:#66d9ef&#34;&gt;head&lt;/span&gt;(post1[,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
hist(post1[,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
bayesplot&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;ppc_dens_overlay(df.r&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;rt, post1[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, ])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The results show us that the modelling the subject level and item level variance was worthwhile in that both the random intercept variance estimates are substantially above zero. Additionally, the estimates align closely with those of Sorensen. However, the estimate for the difference between the reading times continues to represent only weak evidence of an effect.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; Family: lognormal 
  Links: mu = identity; sigma = identity 
Formula: rt ~ so + (1 | subj) + (1 | item) 
   Data: df.r (Number of observations: 547) 
Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1; 
         total post-warmup samples = 2000
    ICs: LOO = NA; WAIC = NA; R2 = NA
 
Group-Level Effects: 
~item (Number of levels: 15) 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.20      0.05     0.12     0.32        655 1.00

~subj (Number of levels: 37) 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.26      0.04     0.19     0.35        867 1.00

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
Intercept     6.06      0.07     5.92     6.21        588 1.01
so           -0.04      0.02    -0.08     0.01       2000 1.00

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma     0.52      0.02     0.49     0.55       2000 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we introduce varying slopes into the model, which allows us to characterise the variation in the &lt;strong&gt;difference&lt;/strong&gt; in reading time across individuals and items. As per Sorensen, we initially prohibit correlation between the varying interecpts and slopes. The required implementation is as follows.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;df.r &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get.data()
&lt;span style=&#34;color:#75715e&#34;&gt;# The latter (-1 + ) part prevents correlation between random effects&lt;/span&gt;
(priors &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get_prior(bf(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
                         (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
                         (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item)),   
                    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
                    family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal()))
priors&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prior[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal(0, 10)&amp;#34;&lt;/span&gt;
blm3 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; brm(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
              (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
              (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item), 
            data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
            family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal(),
            prior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; priors,
            control &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;list&lt;/span&gt;(max_treedepth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;),
            iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;,
            chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, cores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, seed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5453&lt;/span&gt;, save_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;brm1.stan&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(blm3)
VarCorr(blm3)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;While there is evidence for including the random slopes, the estimate of the difference between subject and object relatives has weakened.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Family: lognormal 
  Links: mu = identity; sigma = identity 
Formula: rt ~ so + (1 | subj) + (-1 + so | subj) + (1 | item) + (-1 + so | item) 
   Data: df.r (Number of observations: 547) 
Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1; 
         total post-warmup samples = 2000
    ICs: LOO = NA; WAIC = NA; R2 = NA
 
Group-Level Effects: 
~item (Number of levels: 15) 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.20      0.05     0.12     0.32        797 1.00
sd(so)            0.04      0.03     0.00     0.11        782 1.00

~subj (Number of levels: 37) 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.25      0.04     0.18     0.34        668 1.01
sd(so)            0.06      0.03     0.00     0.13        619 1.00

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
Intercept     6.06      0.08     5.92     6.22        458 1.00
so           -0.04      0.03    -0.09     0.02       2000 1.00

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma     0.52      0.02     0.49     0.55       2000 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we remove the restriction on correlation between the varying slopes and intercepts as implemented below.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;df.r &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get.data()
(priors &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; get_prior(bf(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
                          (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
                          (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item)),
                     data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
                     family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal()))
priors&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;prior[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal(0, 10)&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# mypriors1 &amp;lt;- c(brms::set_prior(&amp;#34;cauchy(0, 2.5)&amp;#34;, class = &amp;#34;b&amp;#34;))&lt;/span&gt;
blm4 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; brm(rt &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
              (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;subj) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
              (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; so&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item), 
            data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df.r,
            family &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lognormal(),
            prior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; priors,
            control &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;list&lt;/span&gt;(max_treedepth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;),
            iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;,
            chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, cores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, seed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5453&lt;/span&gt;, save_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;brm1.stan&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(blm4)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The results suggest no correlation between the varying intercepts and slopes for the item but a negative correlation between the person level varying intercepts and slopes. The implication is that if a person has a slower than average reading time then they will read object relatives.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; Family: lognormal 
  Links: mu = identity; sigma = identity 
Formula: rt ~ so + (1 + so | subj) + (1 + so | item) 
   Data: df.r (Number of observations: 547) 
Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1; 
         total post-warmup samples = 2000
    ICs: LOO = NA; WAIC = NA; R2 = NA
 
Group-Level Effects: 
~item (Number of levels: 15) 
                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)         0.21      0.05     0.13     0.33        660 1.00
sd(so)                0.04      0.03     0.00     0.10        961 1.00
cor(Intercept,so)    -0.00      0.53    -0.92     0.92       2000 1.00

~subj (Number of levels: 37) 
                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)         0.25      0.04     0.19     0.34        624 1.00
sd(so)                0.07      0.03     0.01     0.13        680 1.00
cor(Intercept,so)    -0.61      0.30    -0.98     0.16       1392 1.00

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
Intercept     6.06      0.07     5.92     6.21        492 1.00
so           -0.03      0.03    -0.09     0.02       1160 1.00

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma     0.51      0.02     0.48     0.55       2000 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unfortunately, that is all I have time for today. Hopefully, I will get an opportunity not to far in the future to check the interpretation and add some more details.&lt;/p&gt;

&lt;!-- 
## To do

1. Prior predictive - how sane are our priors?
1. Correlation between the covariates?
2. varying intercepts 45 mins
3. varying intercepts varying slopes 45 mins
4. correlation between the two 40 mins
5. conclusions



Of course, one may want to simplify the model for reasons of parsimony, or easier interpretability. Model selection can be carried out by evaluating predictive performance of the model, with methods such as Leave One Out (LOO) Cross-validation, or by using information criteria like the Watanabe Akaike (or Widely Available) Information Criterion (WAIC). See Nicenboim and Vasishth (2016) for discussion and example code.


&lt;script src=&#34;//gist.github.com/t-student/b93167cf529607038406.js&#34;&gt;&lt;/script&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;section&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;id&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;main&amp;#34;&lt;/span&gt;&amp;gt;
  &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;
   &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;h1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;id&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;title&amp;#34;&lt;/span&gt;&amp;gt;{{ .Title }}&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;h1&lt;/span&gt;&amp;gt;
    {{ range .Data.Pages }}
        {{ .Render &amp;#34;summary&amp;#34;}}
    {{ end }}
  &amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;section&lt;/span&gt;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/w7Ft2ymGmfc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34; title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


--&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Cauchy_distribution&#34; target=&#34;_blank&#34;&gt;Cauchy&lt;/a&gt; distribution is truly quite a bizarre, some would say pathological, distribution as neither the expeccted value nor variance are defined. It also ryhmes with grouchy - no wonder.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Referral for Expert Physical Activity Counseling: A Pragmatic RCT</title>
      <link>https://t-student.github.io/publication/newcoach01/</link>
      <pubDate>Sun, 01 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://t-student.github.io/publication/newcoach01/</guid>
      <description>&lt;!-- More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code. --&gt;
</description>
    </item>
    
    <item>
      <title>Effects of Assault Type on Cognitive Behaviour Therapy for Coexisting Depression and Alcohol Misuse</title>
      <link>https://t-student.github.io/publication/bailey2017/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://t-student.github.io/publication/bailey2017/</guid>
      <description>&lt;!-- More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code. --&gt;
</description>
    </item>
    
    <item>
      <title>Disparities in the incidence of acute myocardial infarction: long-term trends from the Hunter region</title>
      <link>https://t-student.github.io/publication/davies2017/</link>
      <pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://t-student.github.io/publication/davies2017/</guid>
      <description>&lt;!-- More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code. --&gt;
</description>
    </item>
    
    <item>
      <title>Insulin resistance correlates with maculopathy and severity of retinopathy in young adults with Type 1 Diabetes Mellitus</title>
      <link>https://t-student.github.io/publication/rowe2017/</link>
      <pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://t-student.github.io/publication/rowe2017/</guid>
      <description>&lt;!-- More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code. --&gt;
</description>
    </item>
    
    <item>
      <title>A single-arm longitudinal study to evaluate a decision aid for women who have been offered neoadjuvant systemic therapy for operable breast cancer (ANZ1301 DOMINO)</title>
      <link>https://t-student.github.io/publication/zdenkowski2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://t-student.github.io/publication/zdenkowski2017/</guid>
      <description>&lt;!-- More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code. --&gt;
</description>
    </item>
    
  </channel>
</rss>
